{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch numpy gudhi -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"בחופשה האחרונה שלנו, נסענו להכיר את היופיים של מדבר הנגב. בין אם מדובר בצוקים המרשימים, בחי הבר המיוחד, או בשקט המוחלט, יש משהו מאוד מיוחד במדבר. אחת החוויות המרגשות ביותר שלנו הייתה לצפות בזרחת השמש מעל המדבר. האור המתפשט מאחורי ההרים, השמים המשתנים מאוד מהיר מאופל לתכלת, והשלווה המוחלטת שאפשר רק במדבר, הכל הפך את החוויה לבלתי נשכחת\", \n",
    "          \n",
    "          \"במהלך שנת הלימודים הראשונה שלי באוניברסיטה, הצטרפתי לקבוצת טיול שהגיעה להר האייפל. למרות הקור החודר, הייתי מחויב לעלות לפסגה בכל בוקר, כדי לצפות בזרחת השמש מעל פריס\", \n",
    "          \n",
    "          \"הייתי מתעורר בבוקר מוקדם, לפני כולם, כדי לצפות בזרחת השמש. היו ימים שהשמים היו מלאים בגוונים של ורוד וכתום, והאוויר הקר היה ממלא את הריאות. הייתי נושם את השקט, מאזין לשירת הציפורים, ומרגיש את היום החדש שמתחיל.\", \n",
    "          \n",
    "          \"הייתה לי הרגל לצפות בזרחת השמש כאשר הייתי טסה למקומות רחוקים. הייתי מתמקדת באור הזהב של השמש שהתפשט על פני האופק. זה היה רגע של שקט ושלווה, שבו הייתי מרגישה את האפשרויות של היום שלפני.\", \n",
    "          \n",
    "          \"אחד הדברים שאני ממש אוהב לעשות בחופשות הוא לצפות בזרחת השמש על גג המלון. אין דבר יותר מרגיע מאשר לשבת עם כוס קפה ביד, להתבונן בנוף, ולראות איך העולם מתעורר לחיים.\", \n",
    "          \n",
    "          \"במהלך ההליכה, עצרנו לרגע כדי לצפות בזרחת השמש. האור הראשוני של היום הזהיר את השמיים בצבעים של זהב, ואנחנו ישבנו שם בשקט, מתפללים ליום טוב.\", \n",
    "          \n",
    "          \"אני מאמין שאין דבר מרגש יותר מ לצפות בזרחת השמש. כאשר האור הראשונים מתחילים להתפשט באופק, אתה מרגיש כאילו אתה חלק ממשהו גדול מאוד. זה מזכיר לי כמה העולם הזה גדול ויפה.\", \n",
    "          \n",
    "          \"אחת הפעמים המיוחדות ביותר שבהן הזמנתי לצפות בזרחת השמש הייתה בחופשה שלי בהודו. הייתי מתעורר מוקדם, לפני כל העולם, ומשתקף למראה המרהיבה של השמש המתעלה מעל האוקיינוס. זה היה חוויה שאני לעולם לא אשכח.\", \n",
    "          \n",
    "          \"אני אוהב לצפות בזרחת השמש מהחלון שלי. זה נותן לי את האנרגיה להתחיל את היום. אני אפילו מקדיש כמה דקות בכל בוקר לקחת כוס קפה, לשבת מול החלון, ולהשתקף במראה המדהים הזה.\", \n",
    "          \n",
    "          \"בראשית, אני אוהב לצפות בזרחת השמש מהמרפסת שלי. זה מזכיר לי את היופי של העולם, את התקווה של יום חדש, ואת החיים הממשיכים להתפתח בכל יום. כל זריחה מציגה תמונה שונה, נוף חדש שממלא אותי בתחושת התרגשות והתפעלות.\", \n",
    "          \n",
    "          \"היום האחרון שלי ביפן היה יום מיוחד. יצאתי להליך מוקדם בבוקר, כדי לצפות בזרחת השמש מעל הר הפוג'. האור הראשוני של היום מאיר את השיחים המקופים בשלג, מצייר תמונה יפהפיה שאני לעולם לא אשכח.\", \n",
    "          \n",
    "          \"אחד החוויות המרגשות ביותר שלי היתה לצפות בזרחת השמש מעל הפירמידות במצרים. האור החום החודר את השחקים, מאיר את האבנים העתיקות, ומעניק להם מראה של זהב. זה היה רגע של התבוננות והתפעלות על ההיסטוריה שלנו.\", \n",
    "          \n",
    "          \"כאשר אני מטייל בים, אני מתכנן לצפות בזרחת השמש מהחוף. אין דבר מרהיב יותר מלראות את האור הראשון של היום מתפשט על גלי הים, משנה את צבעם לגוונים של זהב ואורנג'. זה הופך את החוויה של ההליכה למשהו יוצא דופן.\", \n",
    "          \n",
    "          \"האלפים היה חלום שלי. כשהגעתי לשם, הייתי עייף אבל מרוצה. לצפות בזרחת השמש מהפסגה, כשהאור העדין של השחר התחיל להתפשט על השפעי השלג הלבנים, היה חוויה בלתי נשכחת. העולם התמלא בנופים שלא ראיתי מעולם. זה היה מרגע של שלווה ושקט, שהיה שווה את כל המאמץ.\", \n",
    "          \n",
    "          \"אחרי שהוא התעורר מהשנה, איזיק הכין לעצמו כוס קפה והולך להסתובב בגן הפרטי שלו. זו הייתה הדרך האהובה עליו להתחיל את היום - לצפות בזרחת השמש ולשמוע את הציפורים מצפצפות.\", \n",
    "          \n",
    "          \"את חייבת לצפות בזרחת השמש מהחוף שלנו, אמר יגאל למרים, כאשר הם הגיעו לבית הנופש של המשפחה. זו תחוויה בלתי נשכחת, משהו שתזכורי לעוד שנים.\",\n",
    "          \n",
    "          \"בזמן שהכל בעיר עדיין ישן, רבקה מתעוררת בשעה המוקדמת ביותר שאפשר, מתארגנת, ויוצאת לרוץ. היא אוהבת את השקט של אותן שעות, והמראה של העיר שמתעוררת לחיים. אבל מעל כל, זה הזמן היחיד שהיא יכולה לצפות בזרחת השמש בלי להיות מופרעת.\",\n",
    "\n",
    "          \"לשפת האגם הגיעה מיה, המצלמה שלה כבר מוכנה לפעולה. היא התיישבה בשקט, מצפה לרגע הנכון. היא יודעת שממש בקרוב, היא תהיה מסוגלת לצפות בזרחת השמש, והיא רוצה לתפוס את הרגע המושלם בתמונה.\", \n",
    "\n",
    "          \"אחד הדברים המרגשים ביותר בנסיעה לאילת הוא ההזדמנות לצפות בזרחת השמש מעל המדבר. השמים משנים את צורתם מכל הכיוונים, מתוך כך מתמלאים בצבעים רבים, מאוד רומנטי. זהו זמן מיוחד להיות בהם, ולהרגיש את השקט שממלא את האוויר.\", \n",
    "\n",
    "          \"הלכתי לשבת על החוף, מחכה לצפות בזרחת השמש. הים היה שקט ומנוחה, האור הפליד התחיל להתפשט באופק. כשהשמש קמה, היא הפכה את השמים לפריים של צבעים מרהיבים. זה היה רגע של שלווה ושקט, שהגיע לפיקו בזריחה המרהיבה.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import BertModel, BertTokenizerFast\n",
    "from transformers import AutoTokenizer, AutoModel \n",
    "import transformers\n",
    "from scipy.spatial import distance_matrix\n",
    "import gudhi as gd\n",
    "from gudhi.hera import wasserstein_distance\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def compute_output_model(tokenizer, model, sentence, layer, head):\n",
    "    # Load pre-trained model\n",
    "\n",
    "    # Tokenize input and convert to tensor\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "\n",
    "    # Forward pass\n",
    "    # Specify `output_hidden_states=True` when calling the model\n",
    "    outputs = model(**inputs, output_attentions=True, output_hidden_states=True)\n",
    "\n",
    "    # Obtain the attention weights\n",
    "    attentions = outputs.attentions\n",
    "\n",
    "    # Obtain the attention weights for the specific layer and head\n",
    "    S = attentions[layer][0, head]\n",
    "\n",
    "    # Obtain the value vectors\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        hidden_states = outputs.hidden_states[layer]\n",
    "        all_W_v = model.encoder.layer[layer].attention.self.value.weight\n",
    "        num_heads = model.config.num_attention_heads\n",
    "        head_dim = model.config.hidden_size // num_heads\n",
    "        W_v_heads = all_W_v.view(num_heads, head_dim, model.config.hidden_size)\n",
    "        W_v = W_v_heads[head]\n",
    "        V = torch.matmul(hidden_states, W_v.t())\n",
    "\n",
    "    # Compute the output O\n",
    "    O = torch.matmul(S, V)\n",
    "\n",
    "    return O\n",
    "\n",
    "\n",
    "\n",
    "def compute_phrase_distances_and_homology(tokenizer, context_vectors, sentence, phrase):\n",
    "    # Initialize the tokenizer\n",
    "\n",
    "    # Tokenize the sentence and the phrase\n",
    "    sentence_tokens = tokenizer.encode(sentence, add_special_tokens=False)\n",
    "    phrase_tokens = tokenizer.encode(phrase, add_special_tokens=False)\n",
    "\n",
    "    # Find the indices of the phrase tokens in the sentence\n",
    "    phrase_indices = []\n",
    "    phrase_length = len(phrase_tokens)\n",
    "    for i in range(len(sentence_tokens) - phrase_length + 1):\n",
    "        if sentence_tokens[i:i+phrase_length] == phrase_tokens:\n",
    "            phrase_indices.extend(range(i, i+phrase_length))\n",
    "            break\n",
    "\n",
    "    # Extract the context vectors for the phrase\n",
    "    phrase_context_vectors = context_vectors[0, phrase_indices]\n",
    "\n",
    "    # Detach the tensor and convert to numpy array\n",
    "    phrase_context_vectors_np = phrase_context_vectors.detach().numpy()\n",
    "\n",
    "    # Compute the pairwise Euclidean distances among the phrase context vectors\n",
    "    distances = distance_matrix(phrase_context_vectors_np, phrase_context_vectors_np)\n",
    "\n",
    "    # Compute the persistent homology of the distance matrix\n",
    "    rips_complex = gd.RipsComplex(distance_matrix=distances, max_edge_length=np.max(distances))\n",
    "    simplex_tree = rips_complex.create_simplex_tree(max_dimension=2)\n",
    "    persistent_homology = simplex_tree.persistence(min_persistence=0.001)\n",
    "\n",
    "    return persistent_homology\n",
    "\n",
    "\n",
    "\n",
    "def transform_persistence_diagram(diagram):\n",
    "    # Remove the dimension from each feature and return the transformed diagram\n",
    "    return [(birth, death) for dimension, (birth, death) in diagram]\n",
    "\n",
    "\n",
    "\n",
    "def compute_wasserstein_distances(persistence_diagrams, p=2):\n",
    "    n = len(persistence_diagrams)\n",
    "    distances = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            diagram1 = transform_persistence_diagram(persistence_diagrams[i])\n",
    "            diagram2 = transform_persistence_diagram(persistence_diagrams[j])\n",
    "            distance = wasserstein_distance(diagram1, diagram2, order=1., internal_p=2.)\n",
    "            distances[i, j] = distance\n",
    "            distances[j, i] = distance\n",
    "    return distances\n",
    "\n",
    "\n",
    "\n",
    "def count_negative_entries_below_diagonal(matrix):\n",
    "    count = 0\n",
    "    total = 0\n",
    "    n = len(matrix)\n",
    "    for i in range(n):\n",
    "        for j in range(i):\n",
    "            if matrix[i][j] < 0:\n",
    "                count += 1\n",
    "            total += 1\n",
    "    return count, total"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the context vectors for all layers and heads for the first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased', output_attentions=True)\n",
    "\n",
    "# Get the number of layers and heads in the model\n",
    "num_layers = model.config.num_hidden_layers\n",
    "num_heads = model.config.num_attention_heads\n",
    "\n",
    "context = []\n",
    "for i in range(len(text)-13):\n",
    "    sentence_context = []\n",
    "    for layer in range(num_layers):\n",
    "        layer_context = []\n",
    "        for head in range(num_heads):\n",
    "            layer_context.append(compute_output_model(tokenizer, model, text[i], layer, head))\n",
    "        sentence_context.append(layer_context)\n",
    "    context.append(sentence_context)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the context vectors for the first model for `paragraph`, `layer`, and `head`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 65, 64])\n",
      "tensor([[[-0.5237,  0.2422,  0.1121,  ...,  0.0144, -0.1483,  0.1990],\n",
      "         [-0.3909, -0.0597, -0.0941,  ...,  0.0906,  0.0752,  0.1344],\n",
      "         [ 0.4456, -1.0985,  0.0814,  ..., -0.0174, -0.3926, -0.3714],\n",
      "         ...,\n",
      "         [-0.0631,  0.6939, -0.0289,  ..., -0.1524, -0.4916,  0.1107],\n",
      "         [-0.5366,  0.3356,  0.1125,  ..., -0.0021, -0.1657,  0.2117],\n",
      "         [-0.5016,  0.3447,  0.0737,  ..., -0.0063, -0.1773,  0.2103]]],\n",
      "       grad_fn=<CloneBackward0>)\n"
     ]
    }
   ],
   "source": [
    "paragraph = len(text)-14\n",
    "layer = 11\n",
    "head = 11\n",
    "\n",
    "print(context[paragraph][layer][head].shape)\n",
    "print(context[paragraph][layer][head])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the context vectors for all layers and heads for the second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at onlplab/alephbert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at onlplab/alephbert-base and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer_2 = BertTokenizer.from_pretrained('onlplab/alephbert-base')\n",
    "model_2 = BertModel.from_pretrained('onlplab/alephbert-base', output_attentions=True)\n",
    "\n",
    "# Get the number of layers and heads in the model\n",
    "num_layers = model_2.config.num_hidden_layers\n",
    "num_heads = model_2.config.num_attention_heads\n",
    "\n",
    "context_2 = []\n",
    "for i in range(len(text)-13):\n",
    "    sentence_context_2 = []\n",
    "    for layer in range(num_layers):\n",
    "        layer_context_2 = []\n",
    "        for head in range(num_heads):\n",
    "            layer_context_2.append(compute_output_model(tokenizer_2, model_2, text[i], layer, head))\n",
    "        sentence_context_2.append(layer_context_2)\n",
    "    context_2.append(sentence_context_2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the context vectors for the second model for `paragraph`, `layer`, and `head`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 39, 64])\n",
      "tensor([[[-0.2489, -0.1003, -0.1082,  ...,  0.3224,  0.2770,  0.2138],\n",
      "         [-0.0090, -0.0289, -0.0112,  ...,  0.0417,  0.0375,  0.0492],\n",
      "         [-0.0215, -0.0292,  0.0039,  ...,  0.0391,  0.0482,  0.0245],\n",
      "         ...,\n",
      "         [ 0.0724, -0.0199, -0.0335,  ...,  0.1791,  0.0585,  0.0575],\n",
      "         [ 0.0517, -0.0192,  0.0675,  ...,  0.0278,  0.0410, -0.0075],\n",
      "         [-0.0945, -0.0731, -0.0540,  ...,  0.3514,  0.2240,  0.2213]]],\n",
      "       grad_fn=<CloneBackward0>)\n"
     ]
    }
   ],
   "source": [
    "paragraph = len(text)-14\n",
    "layer = 11\n",
    "head = 11\n",
    "\n",
    "print(context_2[paragraph][layer][head].shape)\n",
    "print(context_2[paragraph][layer][head])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# Get the number of layers and heads in the model\n",
    "num_layers = model.config.num_hidden_layers\n",
    "num_heads = model.config.num_attention_heads\n",
    "\n",
    "persistent_homology = []\n",
    "\n",
    "for i in range(len(text)-13):\n",
    "    sentence_persistent_homology = []\n",
    "    for layer in range(num_layers):\n",
    "        layer_persistent_homology = []\n",
    "        for head in range(num_heads):\n",
    "            layer_persistent_homology.append(compute_phrase_distances_and_homology(tokenizer, context[i][layer][head], text[i], \"לצפות בזרחת השמש\"))\n",
    "        sentence_persistent_homology.append(layer_persistent_homology)\n",
    "    persistent_homology.append(sentence_persistent_homology)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, (0.0, inf)),\n",
       " (0, (0.0, 7.050955809760106)),\n",
       " (0, (0.0, 6.268928481072075)),\n",
       " (0, (0.0, 6.032945087082421)),\n",
       " (0, (0.0, 5.809649533843446)),\n",
       " (0, (0.0, 5.575215698655618)),\n",
       " (0, (0.0, 5.284121765028418)),\n",
       " (0, (0.0, 4.983391203164792))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persistent_homology[paragraph][layer][head]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_2 = BertTokenizer.from_pretrained('onlplab/alephbert-base')\n",
    "\n",
    "# Get the number of layers and heads in the model\n",
    "num_layers = model_2.config.num_hidden_layers\n",
    "num_heads = model_2.config.num_attention_heads\n",
    "\n",
    "persistent_homology_2 = []\n",
    "\n",
    "for i in range(len(text)-13):\n",
    "    sentence_persistent_homology_2 = []\n",
    "    for layer in range(num_layers):\n",
    "        layer_persistent_homology_2 = []\n",
    "        for head in range(num_heads):\n",
    "            layer_persistent_homology_2.append(compute_phrase_distances_and_homology(tokenizer_2, context_2[i][layer][head], text[i], \"לצפות בזרחת השמש\"))\n",
    "        sentence_persistent_homology_2.append(layer_persistent_homology_2)\n",
    "    persistent_homology_2.append(sentence_persistent_homology_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of layers and heads in the model\n",
    "num_layers = model.config.num_hidden_layers\n",
    "num_heads = model.config.num_attention_heads\n",
    "\n",
    "persistence_diagrams = []\n",
    "\n",
    "for i in range(len(text)-13):\n",
    "    sentence_persistence_diagrams = []\n",
    "    for layer in range(num_layers):\n",
    "        layer_persistence_diagrams = []\n",
    "        for head in range(num_heads):\n",
    "            layer_persistence_diagrams.append(persistent_homology[i][layer][head])\n",
    "        sentence_persistence_diagrams.append(layer_persistence_diagrams)\n",
    "    persistence_diagrams.append(sentence_persistence_diagrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of layers and heads in the model\n",
    "num_layers = model_2.config.num_hidden_layers\n",
    "num_heads = model_2.config.num_attention_heads\n",
    "\n",
    "persistence_diagrams_2 = []\n",
    "\n",
    "for i in range(len(text)-13):\n",
    "    sentence_persistence_diagrams_2 = []\n",
    "    for layer in range(num_layers):\n",
    "        layer_persistence_diagrams_2 = []\n",
    "        for head in range(num_heads):\n",
    "            layer_persistence_diagrams_2.append(persistent_homology_2[i][layer][head])\n",
    "        sentence_persistence_diagrams_2.append(layer_persistence_diagrams_2)\n",
    "    persistence_diagrams_2.append(sentence_persistence_diagrams_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of layers and heads in the model\n",
    "num_layers = model.config.num_hidden_layers\n",
    "num_heads = model.config.num_attention_heads\n",
    "\n",
    "# Initialize w_distances\n",
    "w_distances = [[None for _ in range(num_heads)] for _ in range(num_layers)]\n",
    "\n",
    "for layer in range(num_layers):\n",
    "    for head in range(num_heads):\n",
    "        w_distances[layer][head] = compute_wasserstein_distances([persistent_homology[paragraph][layer][head] for paragraph in range(len(text)-13)])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Matrices for `layer` and `head` of the first model\n",
    "\n",
    "Here we print the Wasserstein distance matrix giving the pairwise Wasserstein distances between each pair of persistence diagrams for the phrase \"לצפות בזרחת השמש\" in each of the contexts `text[i]` (we have restricted to a particular range of `i` values due to computational limitations). Note here, we have a $7 \\times 7$ distance matrix because we have restricted to `len(text)-13` contexts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 7)\n",
      "[[0.         3.96315915 3.57209374 2.37396443 4.66978305 2.25615631\n",
      "  5.29183137]\n",
      " [3.96315915 0.         7.42185424 6.22372493 8.51954355 3.14275\n",
      "  1.58456378]\n",
      " [3.57209374 7.42185424 0.         2.06065268 1.73980241 4.27910424\n",
      "  8.75052646]\n",
      " [2.37396443 6.22372493 2.06065268 0.         2.32265784 3.51076679\n",
      "  7.55239715]\n",
      " [4.66978305 8.51954355 1.73980241 2.32265784 0.         5.37679355\n",
      "  9.84821577]\n",
      " [2.25615631 3.14275    4.27910424 3.51076679 5.37679355 0.\n",
      "  4.47142222]\n",
      " [5.29183137 1.58456378 8.75052646 7.55239715 9.84821577 4.47142222\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(w_distances[layer][head].shape)\n",
    "print(w_distances[layer][head])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of layers and heads in the model\n",
    "num_layers = model_2.config.num_hidden_layers\n",
    "num_heads = model_2.config.num_attention_heads\n",
    "\n",
    "# Initialize w_distances\n",
    "w_distances_2 = [[None for _ in range(num_heads)] for _ in range(num_layers)]\n",
    "\n",
    "for layer in range(num_layers):\n",
    "    for head in range(num_heads):\n",
    "        w_distances_2[layer][head] = compute_wasserstein_distances([persistent_homology_2[paragraph][layer][head] for paragraph in range(len(text)-13)])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Matrices for `layer` and `head` of the second model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 7)\n",
      "[[0.         0.07515095 0.0845273  0.7428543  0.03266424 0.0595901\n",
      "  0.9363218 ]\n",
      " [0.07515095 0.         0.11115083 0.72884094 0.04248671 0.13474105\n",
      "  0.98512428]\n",
      " [0.0845273  0.11115083 0.         0.76863392 0.09075016 0.09187135\n",
      "  0.87803772]\n",
      " [0.7428543  0.72884094 0.76863392 0.         0.73620099 0.79467325\n",
      "  0.30408532]\n",
      " [0.03266424 0.04248671 0.09075016 0.73620099 0.         0.09225434\n",
      "  0.96148918]\n",
      " [0.0595901  0.13474105 0.09187135 0.79467325 0.09225434 0.\n",
      "  0.93537416]\n",
      " [0.9363218  0.98512428 0.87803772 0.30408532 0.96148918 0.93537416\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(w_distances_2[layer][head].shape)\n",
    "print(w_distances_2[layer][head])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentages of Performance\n",
    "\n",
    "This next block of code will create a $144 \\times 144$ array (or more accurately a $12 \\times 12 \\times 12 \\times 12$ array) to store the percentages indication what percentage of entries of the matrices `w_distances[layer_1][head_1] - w_distances_2[layer_2][head_2]` are negative. This effectively compares how well the persistent homology is preserved by one head in one model to how well the persistent homology is preserved a second head in a second layer of a second model. If the percentage of negative entries is high, then the matirx `w_distances_2[layer_2][head_2]` is larger in more places than not, indcating that the second model's Wasserstein distances are higher much more often than not. This means the second model is *worse* at preserving persistent homology. On the other hand, if the percentage of the entries in `w_distances[layer_1][head_1] - w_distances_2[layer_2][head_2]` then the first model's attention head outperforms the second model's attention head at preserving the persistent homology. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 12, 12, 12)\n",
      "Percentages of negative entries below the diagonal:  [[[[ 76.19047619  90.47619048  90.47619048 ...  95.23809524\n",
      "     85.71428571  76.19047619]\n",
      "   [ 76.19047619  95.23809524  95.23809524 ...  61.9047619\n",
      "     95.23809524 100.        ]\n",
      "   [ 19.04761905  80.95238095  85.71428571 ...  66.66666667\n",
      "     85.71428571  66.66666667]\n",
      "   ...\n",
      "   [ 52.38095238  61.9047619   80.95238095 ...  52.38095238\n",
      "     95.23809524  95.23809524]\n",
      "   [100.          95.23809524  95.23809524 ...  57.14285714\n",
      "     47.61904762  23.80952381]\n",
      "   [ 57.14285714 100.          85.71428571 ... 100.\n",
      "     76.19047619  47.61904762]]\n",
      "\n",
      "  [[ 57.14285714  76.19047619  80.95238095 ...  85.71428571\n",
      "     61.9047619   47.61904762]\n",
      "   [ 57.14285714  90.47619048 100.         ...  52.38095238\n",
      "     61.9047619  100.        ]\n",
      "   [  9.52380952  66.66666667  76.19047619 ...  38.0952381\n",
      "     76.19047619  42.85714286]\n",
      "   ...\n",
      "   [ 47.61904762  33.33333333  66.66666667 ...  33.33333333\n",
      "     95.23809524  95.23809524]\n",
      "   [ 76.19047619  95.23809524  80.95238095 ...  19.04761905\n",
      "     47.61904762  14.28571429]\n",
      "   [ 28.57142857 100.          71.42857143 ...  76.19047619\n",
      "     47.61904762  14.28571429]]\n",
      "\n",
      "  [[ 95.23809524  95.23809524  95.23809524 ... 100.\n",
      "     90.47619048  85.71428571]\n",
      "   [ 80.95238095  95.23809524 100.         ...  80.95238095\n",
      "     90.47619048 100.        ]\n",
      "   [ 33.33333333  90.47619048  95.23809524 ...  71.42857143\n",
      "     85.71428571  90.47619048]\n",
      "   ...\n",
      "   [ 66.66666667  76.19047619  95.23809524 ...  66.66666667\n",
      "    100.          95.23809524]\n",
      "   [100.          95.23809524 100.         ...  57.14285714\n",
      "     52.38095238  42.85714286]\n",
      "   [ 66.66666667 100.          90.47619048 ...  95.23809524\n",
      "     90.47619048  47.61904762]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  9.52380952   9.52380952  33.33333333 ...  19.04761905\n",
      "      4.76190476   0.        ]\n",
      "   [ 23.80952381  47.61904762  52.38095238 ...   0.\n",
      "      0.          42.85714286]\n",
      "   [  0.           0.           0.         ...   0.\n",
      "     14.28571429   0.        ]\n",
      "   ...\n",
      "   [  0.           0.           0.         ...   0.\n",
      "      9.52380952   9.52380952]\n",
      "   [  4.76190476   4.76190476   9.52380952 ...   0.\n",
      "      0.           0.        ]\n",
      "   [  0.          61.9047619    4.76190476 ...   4.76190476\n",
      "      0.           0.        ]]\n",
      "\n",
      "  [[ 85.71428571  90.47619048 100.         ...  95.23809524\n",
      "     71.42857143  71.42857143]\n",
      "   [ 76.19047619  95.23809524 100.         ...  76.19047619\n",
      "     90.47619048 100.        ]\n",
      "   [ 33.33333333  80.95238095  90.47619048 ...  61.9047619\n",
      "     85.71428571  71.42857143]\n",
      "   ...\n",
      "   [ 80.95238095  38.0952381   71.42857143 ...  66.66666667\n",
      "    100.          90.47619048]\n",
      "   [100.         100.         100.         ...  61.9047619\n",
      "     61.9047619   23.80952381]\n",
      "   [ 66.66666667 100.          90.47619048 ...  95.23809524\n",
      "     61.9047619   19.04761905]]\n",
      "\n",
      "  [[ 95.23809524 100.          95.23809524 ... 100.\n",
      "     95.23809524  90.47619048]\n",
      "   [ 80.95238095 100.         100.         ...  76.19047619\n",
      "    100.         100.        ]\n",
      "   [ 38.0952381   90.47619048  95.23809524 ...  85.71428571\n",
      "     90.47619048  90.47619048]\n",
      "   ...\n",
      "   [ 71.42857143  76.19047619  95.23809524 ...  52.38095238\n",
      "    100.         100.        ]\n",
      "   [ 90.47619048 100.          95.23809524 ...  66.66666667\n",
      "     52.38095238  47.61904762]\n",
      "   [ 71.42857143 100.         100.         ...  95.23809524\n",
      "     85.71428571  52.38095238]]]\n",
      "\n",
      "\n",
      " [[[ 80.95238095  90.47619048  85.71428571 ...  95.23809524\n",
      "     76.19047619  71.42857143]\n",
      "   [ 66.66666667  95.23809524 100.         ...  61.9047619\n",
      "     80.95238095 100.        ]\n",
      "   [ 33.33333333  71.42857143  80.95238095 ...  61.9047619\n",
      "     85.71428571  71.42857143]\n",
      "   ...\n",
      "   [ 61.9047619   52.38095238  76.19047619 ...  57.14285714\n",
      "     95.23809524  85.71428571]\n",
      "   [ 95.23809524  90.47619048  90.47619048 ...  52.38095238\n",
      "     52.38095238  42.85714286]\n",
      "   [ 52.38095238 100.          90.47619048 ...  90.47619048\n",
      "     57.14285714  38.0952381 ]]\n",
      "\n",
      "  [[ 95.23809524  95.23809524 100.         ... 100.\n",
      "     90.47619048  85.71428571]\n",
      "   [ 76.19047619  95.23809524 100.         ...  71.42857143\n",
      "     95.23809524 100.        ]\n",
      "   [ 42.85714286  90.47619048  95.23809524 ...  66.66666667\n",
      "     90.47619048  85.71428571]\n",
      "   ...\n",
      "   [ 80.95238095  71.42857143  90.47619048 ...  66.66666667\n",
      "    100.         100.        ]\n",
      "   [100.         100.         100.         ...  66.66666667\n",
      "     61.9047619   23.80952381]\n",
      "   [ 71.42857143 100.          90.47619048 ...  95.23809524\n",
      "     90.47619048  47.61904762]]\n",
      "\n",
      "  [[ 57.14285714  76.19047619  85.71428571 ...  90.47619048\n",
      "     57.14285714  38.0952381 ]\n",
      "   [ 47.61904762  90.47619048 100.         ...  38.0952381\n",
      "     66.66666667  95.23809524]\n",
      "   [ 14.28571429  61.9047619   66.66666667 ...  42.85714286\n",
      "     80.95238095  33.33333333]\n",
      "   ...\n",
      "   [ 47.61904762  38.0952381   61.9047619  ...  38.0952381\n",
      "     85.71428571  85.71428571]\n",
      "   [ 76.19047619  76.19047619  90.47619048 ...  23.80952381\n",
      "     47.61904762   9.52380952]\n",
      "   [ 19.04761905  95.23809524  66.66666667 ...  90.47619048\n",
      "     42.85714286  14.28571429]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 71.42857143 100.          95.23809524 ...  95.23809524\n",
      "     61.9047619   57.14285714]\n",
      "   [ 66.66666667  95.23809524 100.         ...  52.38095238\n",
      "     71.42857143 100.        ]\n",
      "   [  9.52380952  71.42857143  76.19047619 ...  52.38095238\n",
      "     80.95238095  47.61904762]\n",
      "   ...\n",
      "   [ 47.61904762  38.0952381   71.42857143 ...  33.33333333\n",
      "     95.23809524  90.47619048]\n",
      "   [ 85.71428571  80.95238095  95.23809524 ...  42.85714286\n",
      "     42.85714286  28.57142857]\n",
      "   [ 33.33333333 100.          76.19047619 ...  90.47619048\n",
      "     52.38095238  19.04761905]]\n",
      "\n",
      "  [[ 38.0952381   57.14285714  76.19047619 ...  71.42857143\n",
      "     42.85714286  38.0952381 ]\n",
      "   [ 47.61904762  80.95238095  85.71428571 ...  33.33333333\n",
      "     42.85714286  85.71428571]\n",
      "   [  4.76190476  47.61904762  52.38095238 ...  23.80952381\n",
      "     52.38095238  23.80952381]\n",
      "   ...\n",
      "   [ 33.33333333  28.57142857  38.0952381  ...  28.57142857\n",
      "     66.66666667  71.42857143]\n",
      "   [ 57.14285714  47.61904762  76.19047619 ...   9.52380952\n",
      "     38.0952381    9.52380952]\n",
      "   [ 14.28571429 100.          47.61904762 ...  66.66666667\n",
      "     28.57142857   9.52380952]]\n",
      "\n",
      "  [[ 80.95238095  85.71428571  90.47619048 ... 100.\n",
      "     76.19047619  76.19047619]\n",
      "   [ 90.47619048 100.         100.         ...  66.66666667\n",
      "     85.71428571 100.        ]\n",
      "   [ 28.57142857  80.95238095  95.23809524 ...  80.95238095\n",
      "     90.47619048  71.42857143]\n",
      "   ...\n",
      "   [ 57.14285714  52.38095238  80.95238095 ...  52.38095238\n",
      "     95.23809524 100.        ]\n",
      "   [ 85.71428571 100.          95.23809524 ...  61.9047619\n",
      "     57.14285714  38.0952381 ]\n",
      "   [ 52.38095238 100.          85.71428571 ...  90.47619048\n",
      "     57.14285714  52.38095238]]]\n",
      "\n",
      "\n",
      " [[[ 76.19047619  90.47619048  95.23809524 ... 100.\n",
      "     76.19047619  66.66666667]\n",
      "   [ 61.9047619   95.23809524 100.         ...  52.38095238\n",
      "     76.19047619 100.        ]\n",
      "   [ 14.28571429  76.19047619  80.95238095 ...  57.14285714\n",
      "     80.95238095  61.9047619 ]\n",
      "   ...\n",
      "   [ 52.38095238  47.61904762  71.42857143 ...  52.38095238\n",
      "     95.23809524  90.47619048]\n",
      "   [ 90.47619048  90.47619048  90.47619048 ...  42.85714286\n",
      "     47.61904762  19.04761905]\n",
      "   [ 33.33333333 100.          80.95238095 ...  90.47619048\n",
      "     57.14285714  33.33333333]]\n",
      "\n",
      "  [[ 66.66666667  80.95238095  85.71428571 ...  95.23809524\n",
      "     66.66666667  66.66666667]\n",
      "   [ 66.66666667  95.23809524 100.         ...  57.14285714\n",
      "     71.42857143 100.        ]\n",
      "   [ 23.80952381  61.9047619   80.95238095 ...  52.38095238\n",
      "     85.71428571  52.38095238]\n",
      "   ...\n",
      "   [ 47.61904762  42.85714286  71.42857143 ...  52.38095238\n",
      "     95.23809524  90.47619048]\n",
      "   [ 85.71428571 100.          90.47619048 ...  42.85714286\n",
      "     52.38095238  23.80952381]\n",
      "   [ 42.85714286 100.          76.19047619 ...  90.47619048\n",
      "     47.61904762  38.0952381 ]]\n",
      "\n",
      "  [[  9.52380952  33.33333333  47.61904762 ...  19.04761905\n",
      "      4.76190476   0.        ]\n",
      "   [ 23.80952381  80.95238095  71.42857143 ...   9.52380952\n",
      "      9.52380952  61.9047619 ]\n",
      "   [  0.           0.           9.52380952 ...   0.\n",
      "     14.28571429   4.76190476]\n",
      "   ...\n",
      "   [  0.           0.           0.         ...   0.\n",
      "     14.28571429   4.76190476]\n",
      "   [ 14.28571429   0.          33.33333333 ...   0.\n",
      "      0.           0.        ]\n",
      "   [  0.          66.66666667   4.76190476 ...  19.04761905\n",
      "      0.           0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 57.14285714  76.19047619  85.71428571 ...  85.71428571\n",
      "     57.14285714  42.85714286]\n",
      "   [ 57.14285714  90.47619048 100.         ...  47.61904762\n",
      "     57.14285714 100.        ]\n",
      "   [ 14.28571429  42.85714286  66.66666667 ...  42.85714286\n",
      "     66.66666667  33.33333333]\n",
      "   ...\n",
      "   [ 52.38095238  28.57142857  52.38095238 ...  28.57142857\n",
      "     76.19047619  80.95238095]\n",
      "   [ 76.19047619  61.9047619   80.95238095 ...  28.57142857\n",
      "     38.0952381   19.04761905]\n",
      "   [ 28.57142857 100.          71.42857143 ...  71.42857143\n",
      "     38.0952381   23.80952381]]\n",
      "\n",
      "  [[ 95.23809524 100.         100.         ... 100.\n",
      "     90.47619048  90.47619048]\n",
      "   [100.         100.         100.         ...  95.23809524\n",
      "    100.         100.        ]\n",
      "   [ 80.95238095 100.          95.23809524 ...  95.23809524\n",
      "    100.          95.23809524]\n",
      "   ...\n",
      "   [ 90.47619048  76.19047619 100.         ...  90.47619048\n",
      "    100.         100.        ]\n",
      "   [100.         100.         100.         ...  85.71428571\n",
      "     66.66666667  61.9047619 ]\n",
      "   [ 90.47619048 100.         100.         ... 100.\n",
      "     85.71428571  47.61904762]]\n",
      "\n",
      "  [[ 33.33333333  42.85714286  71.42857143 ...  52.38095238\n",
      "     28.57142857  19.04761905]\n",
      "   [ 42.85714286  80.95238095  90.47619048 ...  23.80952381\n",
      "     33.33333333  85.71428571]\n",
      "   [  0.          23.80952381  42.85714286 ...  23.80952381\n",
      "     38.0952381   19.04761905]\n",
      "   ...\n",
      "   [  9.52380952  14.28571429  23.80952381 ...   4.76190476\n",
      "     42.85714286  47.61904762]\n",
      "   [ 52.38095238  33.33333333  57.14285714 ...   9.52380952\n",
      "      4.76190476   0.        ]\n",
      "   [  4.76190476  95.23809524  28.57142857 ...  47.61904762\n",
      "     19.04761905   4.76190476]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[  9.52380952  23.80952381  38.0952381  ...   9.52380952\n",
      "      4.76190476   0.        ]\n",
      "   [ 19.04761905  52.38095238  57.14285714 ...   0.\n",
      "     14.28571429  42.85714286]\n",
      "   [  0.           4.76190476   9.52380952 ...   4.76190476\n",
      "     23.80952381   4.76190476]\n",
      "   ...\n",
      "   [  9.52380952   4.76190476   4.76190476 ...   9.52380952\n",
      "     23.80952381   9.52380952]\n",
      "   [ 19.04761905   9.52380952  19.04761905 ...   4.76190476\n",
      "      4.76190476   0.        ]\n",
      "   [  4.76190476  57.14285714   9.52380952 ...  23.80952381\n",
      "      9.52380952   4.76190476]]\n",
      "\n",
      "  [[  4.76190476   4.76190476  19.04761905 ...   4.76190476\n",
      "      0.           0.        ]\n",
      "   [  4.76190476  19.04761905  28.57142857 ...   0.\n",
      "      0.           9.52380952]\n",
      "   [  0.           0.           0.         ...   0.\n",
      "      0.           0.        ]\n",
      "   ...\n",
      "   [  0.           0.           0.         ...   0.\n",
      "      0.           0.        ]\n",
      "   [  4.76190476   0.           4.76190476 ...   0.\n",
      "      0.           0.        ]\n",
      "   [  0.          33.33333333   0.         ...   0.\n",
      "      0.           0.        ]]\n",
      "\n",
      "  [[ 28.57142857  33.33333333  57.14285714 ...  28.57142857\n",
      "     23.80952381   4.76190476]\n",
      "   [ 28.57142857  71.42857143  80.95238095 ...   0.\n",
      "      9.52380952  66.66666667]\n",
      "   [  0.          14.28571429  23.80952381 ...   4.76190476\n",
      "     38.0952381    0.        ]\n",
      "   ...\n",
      "   [ 14.28571429   0.           9.52380952 ...   4.76190476\n",
      "     28.57142857  23.80952381]\n",
      "   [ 23.80952381   9.52380952  52.38095238 ...   0.\n",
      "     14.28571429   0.        ]\n",
      "   [  4.76190476  85.71428571   9.52380952 ...  33.33333333\n",
      "      4.76190476   4.76190476]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  9.52380952  14.28571429  14.28571429 ...   9.52380952\n",
      "      4.76190476   0.        ]\n",
      "   [  9.52380952  14.28571429  23.80952381 ...   0.\n",
      "      4.76190476  14.28571429]\n",
      "   [  0.           4.76190476   0.         ...   0.\n",
      "      9.52380952   0.        ]\n",
      "   ...\n",
      "   [  0.           0.           0.         ...   0.\n",
      "      9.52380952   4.76190476]\n",
      "   [  9.52380952   4.76190476   0.         ...   0.\n",
      "      0.           0.        ]\n",
      "   [  0.          23.80952381   0.         ...   0.\n",
      "      0.           0.        ]]\n",
      "\n",
      "  [[  0.           4.76190476  23.80952381 ...   4.76190476\n",
      "      0.           0.        ]\n",
      "   [  0.          23.80952381  23.80952381 ...   4.76190476\n",
      "      4.76190476   9.52380952]\n",
      "   [  0.           4.76190476   0.         ...   0.\n",
      "      4.76190476   0.        ]\n",
      "   ...\n",
      "   [  0.           0.           0.         ...   0.\n",
      "      0.          14.28571429]\n",
      "   [  9.52380952   0.           4.76190476 ...   0.\n",
      "      0.           0.        ]\n",
      "   [  0.          38.0952381    0.         ...   4.76190476\n",
      "      0.           0.        ]]\n",
      "\n",
      "  [[ 42.85714286  66.66666667  85.71428571 ...  66.66666667\n",
      "     47.61904762  23.80952381]\n",
      "   [ 47.61904762  90.47619048  90.47619048 ...  33.33333333\n",
      "     47.61904762  95.23809524]\n",
      "   [  0.          42.85714286  61.9047619  ...  28.57142857\n",
      "     61.9047619   19.04761905]\n",
      "   ...\n",
      "   [ 33.33333333  19.04761905  42.85714286 ...  14.28571429\n",
      "     76.19047619  61.9047619 ]\n",
      "   [ 71.42857143  61.9047619   71.42857143 ...   9.52380952\n",
      "     23.80952381   4.76190476]\n",
      "   [  9.52380952  95.23809524  42.85714286 ...  66.66666667\n",
      "     19.04761905   4.76190476]]]\n",
      "\n",
      "\n",
      " [[[ 14.28571429  14.28571429  28.57142857 ...  19.04761905\n",
      "      9.52380952   0.        ]\n",
      "   [ 19.04761905  38.0952381   38.0952381  ...   0.\n",
      "      9.52380952  38.0952381 ]\n",
      "   [  0.           4.76190476   9.52380952 ...   0.\n",
      "     23.80952381   0.        ]\n",
      "   ...\n",
      "   [  0.           0.           9.52380952 ...   0.\n",
      "     14.28571429   9.52380952]\n",
      "   [ 14.28571429   4.76190476  19.04761905 ...   0.\n",
      "      4.76190476   0.        ]\n",
      "   [  0.          47.61904762   4.76190476 ...   4.76190476\n",
      "      0.           0.        ]]\n",
      "\n",
      "  [[ 23.80952381  23.80952381  42.85714286 ...  23.80952381\n",
      "     14.28571429   9.52380952]\n",
      "   [ 28.57142857  61.9047619   71.42857143 ...   9.52380952\n",
      "      9.52380952  52.38095238]\n",
      "   [  0.           0.          19.04761905 ...   4.76190476\n",
      "     19.04761905   4.76190476]\n",
      "   ...\n",
      "   [  4.76190476   4.76190476   4.76190476 ...  14.28571429\n",
      "     23.80952381  23.80952381]\n",
      "   [ 19.04761905   9.52380952  38.0952381  ...   4.76190476\n",
      "     14.28571429   0.        ]\n",
      "   [  4.76190476  76.19047619  19.04761905 ...  23.80952381\n",
      "      4.76190476   4.76190476]]\n",
      "\n",
      "  [[  9.52380952  14.28571429  42.85714286 ...   9.52380952\n",
      "      9.52380952   0.        ]\n",
      "   [ 23.80952381  47.61904762  57.14285714 ...   4.76190476\n",
      "     14.28571429  23.80952381]\n",
      "   [  0.           4.76190476   9.52380952 ...   0.\n",
      "     14.28571429   4.76190476]\n",
      "   ...\n",
      "   [  0.           0.           4.76190476 ...   0.\n",
      "      9.52380952   4.76190476]\n",
      "   [ 19.04761905   0.           9.52380952 ...   0.\n",
      "      0.           4.76190476]\n",
      "   [  0.          61.9047619    4.76190476 ...  14.28571429\n",
      "      0.           0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 19.04761905  23.80952381  47.61904762 ...  28.57142857\n",
      "     14.28571429   0.        ]\n",
      "   [ 19.04761905  61.9047619   57.14285714 ...   4.76190476\n",
      "     14.28571429  52.38095238]\n",
      "   [  0.           9.52380952  23.80952381 ...   4.76190476\n",
      "     28.57142857   4.76190476]\n",
      "   ...\n",
      "   [  0.           0.           4.76190476 ...   0.\n",
      "     19.04761905  14.28571429]\n",
      "   [ 23.80952381   9.52380952  28.57142857 ...   4.76190476\n",
      "      0.           0.        ]\n",
      "   [  0.          71.42857143   9.52380952 ...  14.28571429\n",
      "      4.76190476   0.        ]]\n",
      "\n",
      "  [[  0.          14.28571429  38.0952381  ...  14.28571429\n",
      "     14.28571429   0.        ]\n",
      "   [ 19.04761905  52.38095238  57.14285714 ...   9.52380952\n",
      "     14.28571429  42.85714286]\n",
      "   [  0.          14.28571429  19.04761905 ...   0.\n",
      "     19.04761905   4.76190476]\n",
      "   ...\n",
      "   [  4.76190476   9.52380952   4.76190476 ...   0.\n",
      "     14.28571429  19.04761905]\n",
      "   [ 19.04761905  14.28571429  33.33333333 ...   4.76190476\n",
      "      0.           0.        ]\n",
      "   [  0.          57.14285714   4.76190476 ...  14.28571429\n",
      "      4.76190476   0.        ]]\n",
      "\n",
      "  [[  4.76190476  14.28571429  33.33333333 ...  23.80952381\n",
      "      4.76190476   0.        ]\n",
      "   [ 19.04761905  33.33333333  52.38095238 ...   9.52380952\n",
      "      9.52380952  28.57142857]\n",
      "   [  0.           4.76190476   9.52380952 ...   0.\n",
      "     19.04761905   0.        ]\n",
      "   ...\n",
      "   [  0.           0.           0.         ...   0.\n",
      "      4.76190476  14.28571429]\n",
      "   [ 14.28571429   4.76190476  14.28571429 ...   4.76190476\n",
      "      0.           0.        ]\n",
      "   [  0.          61.9047619    4.76190476 ...  14.28571429\n",
      "      0.           0.        ]]]\n",
      "\n",
      "\n",
      " [[[ 14.28571429  38.0952381   42.85714286 ...  28.57142857\n",
      "     19.04761905   4.76190476]\n",
      "   [ 23.80952381  66.66666667  57.14285714 ...  14.28571429\n",
      "     14.28571429  47.61904762]\n",
      "   [  4.76190476  19.04761905  19.04761905 ...   4.76190476\n",
      "     38.0952381    9.52380952]\n",
      "   ...\n",
      "   [ 14.28571429  14.28571429  14.28571429 ...  14.28571429\n",
      "     28.57142857  28.57142857]\n",
      "   [ 33.33333333  19.04761905  19.04761905 ...   4.76190476\n",
      "     14.28571429   4.76190476]\n",
      "   [  4.76190476  66.66666667  19.04761905 ...  14.28571429\n",
      "     14.28571429   4.76190476]]\n",
      "\n",
      "  [[  4.76190476   4.76190476  38.0952381  ...  19.04761905\n",
      "      4.76190476   4.76190476]\n",
      "   [ 14.28571429  57.14285714  57.14285714 ...   9.52380952\n",
      "      4.76190476  47.61904762]\n",
      "   [  0.           4.76190476   9.52380952 ...  14.28571429\n",
      "     14.28571429   0.        ]\n",
      "   ...\n",
      "   [  0.           0.           4.76190476 ...   0.\n",
      "     14.28571429  19.04761905]\n",
      "   [ 14.28571429  19.04761905  19.04761905 ...   0.\n",
      "      0.           0.        ]\n",
      "   [  0.          76.19047619  19.04761905 ...   9.52380952\n",
      "      4.76190476   0.        ]]\n",
      "\n",
      "  [[  9.52380952  19.04761905  38.0952381  ...  14.28571429\n",
      "     14.28571429   4.76190476]\n",
      "   [ 14.28571429  52.38095238  52.38095238 ...   0.\n",
      "      9.52380952  38.0952381 ]\n",
      "   [  0.           9.52380952   9.52380952 ...   4.76190476\n",
      "     14.28571429   0.        ]\n",
      "   ...\n",
      "   [  4.76190476   0.           9.52380952 ...   0.\n",
      "     14.28571429  14.28571429]\n",
      "   [  9.52380952  14.28571429  19.04761905 ...   4.76190476\n",
      "      4.76190476   4.76190476]\n",
      "   [  0.          57.14285714   9.52380952 ...   9.52380952\n",
      "      4.76190476   0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 19.04761905  23.80952381  52.38095238 ...  28.57142857\n",
      "     14.28571429   4.76190476]\n",
      "   [ 33.33333333  71.42857143  80.95238095 ...   4.76190476\n",
      "     19.04761905  76.19047619]\n",
      "   [  0.          19.04761905  23.80952381 ...   9.52380952\n",
      "     33.33333333   9.52380952]\n",
      "   ...\n",
      "   [  9.52380952  14.28571429  14.28571429 ...   4.76190476\n",
      "     33.33333333  33.33333333]\n",
      "   [ 23.80952381  23.80952381  38.0952381  ...   0.\n",
      "     19.04761905   0.        ]\n",
      "   [  4.76190476  90.47619048  14.28571429 ...  23.80952381\n",
      "     14.28571429   4.76190476]]\n",
      "\n",
      "  [[  9.52380952  23.80952381  38.0952381  ...  19.04761905\n",
      "      9.52380952   0.        ]\n",
      "   [ 19.04761905  47.61904762  52.38095238 ...   4.76190476\n",
      "      4.76190476  38.0952381 ]\n",
      "   [  0.           4.76190476   9.52380952 ...   0.\n",
      "     14.28571429   4.76190476]\n",
      "   ...\n",
      "   [  0.           4.76190476   4.76190476 ...   0.\n",
      "      9.52380952  14.28571429]\n",
      "   [ 19.04761905   0.          14.28571429 ...   0.\n",
      "      0.           0.        ]\n",
      "   [  0.          57.14285714   4.76190476 ...   9.52380952\n",
      "      9.52380952   0.        ]]\n",
      "\n",
      "  [[  4.76190476   4.76190476  38.0952381  ...   4.76190476\n",
      "      4.76190476   0.        ]\n",
      "   [  9.52380952  38.0952381   42.85714286 ...   0.\n",
      "      4.76190476  42.85714286]\n",
      "   [  0.           4.76190476   0.         ...   0.\n",
      "      4.76190476   0.        ]\n",
      "   ...\n",
      "   [  0.           0.           4.76190476 ...   0.\n",
      "      4.76190476   9.52380952]\n",
      "   [ 14.28571429   4.76190476  23.80952381 ...   0.\n",
      "      4.76190476   0.        ]\n",
      "   [  0.          52.38095238   0.         ...  14.28571429\n",
      "      0.           0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "# Create a 4D array to store the percentages\n",
    "percentages = np.zeros((num_layers, num_heads, num_layers, num_heads))\n",
    "\n",
    "# Loop over all pairs of layers and heads\n",
    "for layer_1 in range(num_layers):\n",
    "    for head_1 in range(num_heads):\n",
    "        for layer_2 in range(num_layers):\n",
    "            for head_2 in range(num_heads):\n",
    "                # Compute the difference of their Wasserstein distance matrices\n",
    "                matrix = w_distances[layer_1][head_1] - w_distances_2[layer_2][head_2]\n",
    "\n",
    "                # Count the percentage of negative entries below the diagonal\n",
    "                negative_count, total_count = count_negative_entries_below_diagonal(matrix)\n",
    "                percentage = (negative_count / total_count) * 100\n",
    "\n",
    "                # Store the percentage\n",
    "                percentages[layer_1, head_1, layer_2, head_2] = percentage\n",
    "\n",
    "print(percentages.shape)\n",
    "print(\"Percentages of negative entries below the diagonal: \", percentages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "layer_1 = 11\n",
    "head_1 = 5\n",
    "\n",
    "layer_2 = 1\n",
    "head_2 = 1\n",
    "\n",
    "print(percentages[layer_1][head_1][layer_2][head_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min:  0.0\n",
      "Max:  100.0\n",
      "Mean:  37.688078703703695\n",
      "Median:  28.57142857142857\n",
      "Standard Deviation:  32.925606089374305\n",
      "25th percentile:  9.523809523809524\n",
      "75th percentile:  66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a list to store all entries\n",
    "all_entries = []\n",
    "\n",
    "# Loop over all entries in the 4D array\n",
    "for layer_1 in range(num_layers):\n",
    "    for head_1 in range(num_heads):\n",
    "        for layer_2 in range(num_layers):\n",
    "            for head_2 in range(num_heads):\n",
    "                # Add the entry to the list\n",
    "                all_entries.append(percentages[layer_1, head_1, layer_2, head_2])\n",
    "\n",
    "# Convert the list to a numpy array\n",
    "all_entries = np.array(all_entries)\n",
    "\n",
    "# Compute the statistics\n",
    "min_value = np.min(all_entries)\n",
    "max_value = np.max(all_entries)\n",
    "mean_value = np.mean(all_entries)\n",
    "median_value = np.median(all_entries)\n",
    "std_dev = np.std(all_entries)\n",
    "percentile_25 = np.percentile(all_entries, 25)\n",
    "percentile_75 = np.percentile(all_entries, 75)\n",
    "\n",
    "# Print the statistics\n",
    "print(\"Min: \", min_value)\n",
    "print(\"Max: \", max_value)\n",
    "print(\"Mean: \", mean_value)\n",
    "print(\"Median: \", median_value)\n",
    "print(\"Standard Deviation: \", std_dev)\n",
    "print(\"25th percentile: \", percentile_25)\n",
    "print(\"75th percentile: \", percentile_75)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can tell that a majority of the time the second model `onlplab/alephbert-base` outperforms the first model `bert-base-multilingual-cased` at preserving the persistent homology of the phrase \"לצפות בזרחת השמש\" in the various contexts given by each `text[i]`. However, the distinction is not as clear as it is for some of the other examples. In particular, `onlplab/alephbert-base` only outperforms `bert-base-multilingual-cased` about $62.31\\%$ of the time according to the mean, and about $67.07\\%$ of the time according to the median. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
